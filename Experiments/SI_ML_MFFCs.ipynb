{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgll9g5kIGGa"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speaker = \"Reem\""
      ],
      "metadata": {
        "id": "ymrU_eVbL0DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = f\"/content/drive/MyDrive/thesis_models/mini_dataset/{speaker}/\"\n",
        "output_path = directory_path\n",
        "output_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "93Y9_o38IjXz",
        "outputId": "697328d6-6e92-402b-b858-aa213d01d7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/thesis_models/mini_dataset/Reem/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = os.listdir(directory_path)\n",
        "file_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbn47pG0Iicb",
        "outputId": "b9441e7b-daa6-4104-d1be-2d7b26d2a6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1.m4a',\n",
              " '2.m4a',\n",
              " '3.m4a',\n",
              " '4.m4a',\n",
              " '5.m4a',\n",
              " '6.m4a',\n",
              " '7.m4a',\n",
              " '8.m4a',\n",
              " '9.m4a',\n",
              " '10.m4a',\n",
              " 'Reem.csv',\n",
              " 'Reem_1_3sec2d.csv',\n",
              " 'Reem_3_3sec2d.csv',\n",
              " 'Reem_2_3sec2d.csv',\n",
              " 'Reem_4_3sec2d.csv',\n",
              " 'Reem_5_3sec2d.csv',\n",
              " 'Reem_9_3sec2d.csv',\n",
              " 'Reem_7_3sec2d.csv',\n",
              " 'Reem_6_3sec2d.csv',\n",
              " 'Reem_8_3sec2d.csv',\n",
              " 'Reem_10_3sec2d.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mfccs_mean_vector(mfccs):\n",
        "  mfccs_mean = []\n",
        "  for mfcc_feature in mfccs:\n",
        "      mfccs_mean.append(np.mean(mfcc_feature))\n",
        "  mfccs_mean = np.array(mfccs_mean)\n",
        "  return mfccs_mean"
      ],
      "metadata": {
        "id": "sifstqK9J0MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns = [f'MFCC {i}' for i in range(1, 21)]\n",
        "# columns.append('Speaker')\n",
        "# df = pd.DataFrame(columns=columns)\n",
        "vectors = []\n",
        "i = 1\n",
        "for file_name in file_names:\n",
        "  if file_name.split('.')[-1] != \"m4a\":\n",
        "    continue\n",
        "  file_path = directory_path + file_name\n",
        "  signal, sr = librosa.load(file_path, duration=3)\n",
        "  mfccs = librosa.feature.mfcc(y=signal, n_mfcc=20, sr=sr)\n",
        "  # mfcc_vector = get_mfccs_mean_vector(mfccs)\n",
        "  # mfcc_vector = np.append(mfcc_vector, speaker)\n",
        "  mfcc_vector = mfccs\n",
        "  vectors.append(mfcc_vector)\n",
        "  i += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooblpp8T79If",
        "outputId": "61f64d60-6e63-4f39-fb4f-7dd20d8d0ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-8-a99da02d6030>:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.display.specshow(vectors[9], sr=sr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rYXh6zN78kO_",
        "outputId": "9fa764d5-e97b-45b0-82ee-bd3d999c2475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.QuadMesh at 0x7f2259de5930>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # columns = [f'MFCC {i}' for i in range(1, 21)]\n",
        "# # columns.append('Speaker')\n",
        "# # df = pd.DataFrame(columns=columns)\n",
        "# i = 1\n",
        "# for file_name in file_names:\n",
        "#   if file_name.split('.')[-1] != \"m4a\":\n",
        "#     continue\n",
        "#   file_path = directory_path + file_name\n",
        "#   signal, sr = librosa.load(file_path, duration=3)\n",
        "#   mfccs = librosa.feature.mfcc(y=signal, n_mfcc=20, sr=sr)\n",
        "#   # mfcc_vector = get_mfccs_mean_vector(mfccs)\n",
        "#   # mfcc_vector = np.append(mfcc_vector, speaker)\n",
        "#   mfcc_vector = mfccs\n",
        "#   df = pd.DataFrame(mfcc_vector)\n",
        "#   df.to_csv(f'{output_path}{speaker}_{i}_3sec2d.csv', index=False)\n",
        "#   i += 1\n",
        "# df = pd.read_csv(f'{output_path}{speaker}_{i-1}_3sec2d.csv')\n",
        "# df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PX5RsQej7j-t",
        "outputId": "6db26559-8488-4ec5-de94-c611a43c7410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-41-b4945ae9cae0>:9: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  signal, sr = librosa.load(file_path, duration=3)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0           1           2           3           4           5  \\\n",
              "0  -808.183530 -678.785800 -646.323670 -671.158450 -687.246460 -693.442930   \n",
              "1    68.858890  146.596800  142.424300  124.632960  114.540190  110.753370   \n",
              "2    56.581200   56.137848   60.699158   61.572712   53.038345   52.001724   \n",
              "3    40.496742   50.513958   57.690040   60.829540   52.068836   51.330917   \n",
              "4    25.107958   31.543484   34.788116   40.143570   37.874237   35.628960   \n",
              "5    13.719574   22.262585   27.302687   29.188372   29.559252   34.899460   \n",
              "6     7.400309   16.737888   17.519260   22.728565   22.528677   24.225760   \n",
              "7     5.134473   13.481317   16.497002   20.368069   14.509150   17.061584   \n",
              "8     4.885613    8.869980   12.384069   11.666620    8.762781   14.657253   \n",
              "9     4.854179   12.262621   10.831870    4.002755    9.354394   13.389982   \n",
              "10    4.239115    2.921768    0.449536   -1.447572    8.025484    9.722061   \n",
              "11    3.228742    8.585993   11.038528    5.022841    4.395417    3.941920   \n",
              "12    2.442136    5.416662    3.625821   -2.217569   -2.001754    3.055751   \n",
              "13    2.308006    1.849368    2.648895    3.060864    3.704577    6.603056   \n",
              "14    2.780722    4.516361    4.977440    5.687684    3.321391    4.310385   \n",
              "15    3.477061    2.782973    4.959840    8.554922    8.908003    5.128218   \n",
              "16    4.020112    4.855131    5.163251   14.330421   15.317526    6.801951   \n",
              "17    4.289417    4.392704    5.398010    7.555681    7.504780    8.120828   \n",
              "18    4.416011    6.048285    7.828956    7.707705    7.447975    7.089395   \n",
              "19    4.584046    1.266698    2.853934    3.867961    4.031549    1.301042   \n",
              "\n",
              "             6           7           8           9  ...         120  \\\n",
              "0  -677.385300 -664.436600 -665.951540 -656.567100  ... -686.926760   \n",
              "1   123.019580  133.013300  131.238190  137.419900  ...  113.533905   \n",
              "2    57.648003   59.530987   66.214676   66.139570  ...   47.087160   \n",
              "3    59.335846   59.593330   69.316500   69.503050  ...   57.572760   \n",
              "4    40.197850   42.138480   49.147087   47.194650  ...   39.427032   \n",
              "5    38.809372   37.434776   39.036600   35.642740  ...   37.255714   \n",
              "6    31.314346   27.983013   22.823448   20.503525  ...   27.310856   \n",
              "7    24.823020   20.653173   19.454735   14.869041  ...   21.883310   \n",
              "8    16.756500   12.666725    8.871258    3.851370  ...   14.630124   \n",
              "9    14.233492   10.481882    5.950897    2.667422  ...   15.118452   \n",
              "10   10.611401    8.393124    1.459947    0.641023  ...   11.150479   \n",
              "11   10.484508    8.496041    5.036035   12.292791  ...   15.869504   \n",
              "12    2.921979    1.594232    2.123627    2.591272  ...    3.640095   \n",
              "13    7.588957    9.453242   10.527960    4.816059  ...    8.264572   \n",
              "14    1.644539    4.452641    6.461669    4.538523  ...    6.916524   \n",
              "15    5.568866   10.190098    6.383940    6.805264  ...    4.904903   \n",
              "16    8.997994   11.389247    6.045928    7.115082  ...    8.356026   \n",
              "17    9.922593    7.822845    3.229239    3.489827  ...    6.335666   \n",
              "18    6.667765    4.608913    2.673733    1.044449  ...    7.329278   \n",
              "19   -3.213294   -0.666927   -0.653931   -5.726377  ...    6.354600   \n",
              "\n",
              "           121         122         123         124         125         126  \\\n",
              "0  -687.169600 -693.775150 -698.719700 -691.005600 -683.260860 -682.017460   \n",
              "1   108.759050  101.950424   94.215060  102.491080  113.271190  112.889380   \n",
              "2    49.361020   49.682655   39.593850   43.381294   54.381153   51.978466   \n",
              "3    55.975630   56.301544   47.263810   48.362625   51.610886   51.079790   \n",
              "4    44.102325   43.113290   36.513330   38.983850   39.895500   37.893180   \n",
              "5    34.634880   32.179688   33.542297   36.533836   36.158222   35.150593   \n",
              "6    23.909794   18.724120   21.818403   24.910782   21.403605   21.136051   \n",
              "7    25.639480   23.540054   18.858322   20.297009   21.009579   17.495934   \n",
              "8    15.115923   17.144138   16.288240   16.407455   16.913385    9.809426   \n",
              "9    14.953615   13.677976   15.595757   12.006489   10.840181   10.435387   \n",
              "10   10.347811    4.785758    9.953649    6.019490    2.910423    5.969234   \n",
              "11   11.760733    5.837637   10.689942    8.251028    2.205105    4.517925   \n",
              "12    2.895083    2.217961    4.927725    3.451984    1.138815   -1.782372   \n",
              "13    7.421254   11.416150    8.694925    3.390199    5.608705    6.225214   \n",
              "14    3.872615    5.403200    1.245299   -4.280363   -4.531428   -4.534841   \n",
              "15    4.429753    7.980596    3.414380   -3.402398   -6.213781   -3.878690   \n",
              "16    9.193071   10.429809   10.300892    3.572683   -0.785625    3.086043   \n",
              "17    7.366229    4.571144    3.464195    0.258484   -2.342484   -1.303418   \n",
              "18   10.482709    0.414825    3.431669    7.210251   -0.021464   -5.898850   \n",
              "19    3.372196   -7.436252   -0.069299    3.742786    1.294925   -2.002482   \n",
              "\n",
              "           127         128         129  \n",
              "0  -686.102200 -657.268550 -603.979600  \n",
              "1   111.313934  120.076620  116.322830  \n",
              "2    48.506570   46.493614   36.573006  \n",
              "3    52.486855   45.960335   30.625961  \n",
              "4    35.736343   28.844316   22.874350  \n",
              "5    32.027397   26.254917   17.983868  \n",
              "6    19.617165   16.570320   12.288887  \n",
              "7    13.776319   13.104317    9.069902  \n",
              "8     9.440727    8.185134    5.845839  \n",
              "9     7.242203    7.516584    4.122503  \n",
              "10    8.232852    6.724492    6.033055  \n",
              "11    9.932086    8.678764    4.427045  \n",
              "12   -0.798526    1.381832    2.345471  \n",
              "13    3.567305    1.585533    2.961648  \n",
              "14   -9.869007   -6.401797   -0.532115  \n",
              "15   -9.181259   -2.600746    2.145145  \n",
              "16    0.307965    1.042486    2.162609  \n",
              "17   -1.448322   -0.987339   -0.223155  \n",
              "18   -4.855162   -3.154200    0.083367  \n",
              "19   -7.301378   -4.333294   -0.689210  \n",
              "\n",
              "[20 rows x 130 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de5a6000-3463-4a17-9524-2a08d533bf6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-808.183530</td>\n",
              "      <td>-678.785800</td>\n",
              "      <td>-646.323670</td>\n",
              "      <td>-671.158450</td>\n",
              "      <td>-687.246460</td>\n",
              "      <td>-693.442930</td>\n",
              "      <td>-677.385300</td>\n",
              "      <td>-664.436600</td>\n",
              "      <td>-665.951540</td>\n",
              "      <td>-656.567100</td>\n",
              "      <td>...</td>\n",
              "      <td>-686.926760</td>\n",
              "      <td>-687.169600</td>\n",
              "      <td>-693.775150</td>\n",
              "      <td>-698.719700</td>\n",
              "      <td>-691.005600</td>\n",
              "      <td>-683.260860</td>\n",
              "      <td>-682.017460</td>\n",
              "      <td>-686.102200</td>\n",
              "      <td>-657.268550</td>\n",
              "      <td>-603.979600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68.858890</td>\n",
              "      <td>146.596800</td>\n",
              "      <td>142.424300</td>\n",
              "      <td>124.632960</td>\n",
              "      <td>114.540190</td>\n",
              "      <td>110.753370</td>\n",
              "      <td>123.019580</td>\n",
              "      <td>133.013300</td>\n",
              "      <td>131.238190</td>\n",
              "      <td>137.419900</td>\n",
              "      <td>...</td>\n",
              "      <td>113.533905</td>\n",
              "      <td>108.759050</td>\n",
              "      <td>101.950424</td>\n",
              "      <td>94.215060</td>\n",
              "      <td>102.491080</td>\n",
              "      <td>113.271190</td>\n",
              "      <td>112.889380</td>\n",
              "      <td>111.313934</td>\n",
              "      <td>120.076620</td>\n",
              "      <td>116.322830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56.581200</td>\n",
              "      <td>56.137848</td>\n",
              "      <td>60.699158</td>\n",
              "      <td>61.572712</td>\n",
              "      <td>53.038345</td>\n",
              "      <td>52.001724</td>\n",
              "      <td>57.648003</td>\n",
              "      <td>59.530987</td>\n",
              "      <td>66.214676</td>\n",
              "      <td>66.139570</td>\n",
              "      <td>...</td>\n",
              "      <td>47.087160</td>\n",
              "      <td>49.361020</td>\n",
              "      <td>49.682655</td>\n",
              "      <td>39.593850</td>\n",
              "      <td>43.381294</td>\n",
              "      <td>54.381153</td>\n",
              "      <td>51.978466</td>\n",
              "      <td>48.506570</td>\n",
              "      <td>46.493614</td>\n",
              "      <td>36.573006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40.496742</td>\n",
              "      <td>50.513958</td>\n",
              "      <td>57.690040</td>\n",
              "      <td>60.829540</td>\n",
              "      <td>52.068836</td>\n",
              "      <td>51.330917</td>\n",
              "      <td>59.335846</td>\n",
              "      <td>59.593330</td>\n",
              "      <td>69.316500</td>\n",
              "      <td>69.503050</td>\n",
              "      <td>...</td>\n",
              "      <td>57.572760</td>\n",
              "      <td>55.975630</td>\n",
              "      <td>56.301544</td>\n",
              "      <td>47.263810</td>\n",
              "      <td>48.362625</td>\n",
              "      <td>51.610886</td>\n",
              "      <td>51.079790</td>\n",
              "      <td>52.486855</td>\n",
              "      <td>45.960335</td>\n",
              "      <td>30.625961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.107958</td>\n",
              "      <td>31.543484</td>\n",
              "      <td>34.788116</td>\n",
              "      <td>40.143570</td>\n",
              "      <td>37.874237</td>\n",
              "      <td>35.628960</td>\n",
              "      <td>40.197850</td>\n",
              "      <td>42.138480</td>\n",
              "      <td>49.147087</td>\n",
              "      <td>47.194650</td>\n",
              "      <td>...</td>\n",
              "      <td>39.427032</td>\n",
              "      <td>44.102325</td>\n",
              "      <td>43.113290</td>\n",
              "      <td>36.513330</td>\n",
              "      <td>38.983850</td>\n",
              "      <td>39.895500</td>\n",
              "      <td>37.893180</td>\n",
              "      <td>35.736343</td>\n",
              "      <td>28.844316</td>\n",
              "      <td>22.874350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13.719574</td>\n",
              "      <td>22.262585</td>\n",
              "      <td>27.302687</td>\n",
              "      <td>29.188372</td>\n",
              "      <td>29.559252</td>\n",
              "      <td>34.899460</td>\n",
              "      <td>38.809372</td>\n",
              "      <td>37.434776</td>\n",
              "      <td>39.036600</td>\n",
              "      <td>35.642740</td>\n",
              "      <td>...</td>\n",
              "      <td>37.255714</td>\n",
              "      <td>34.634880</td>\n",
              "      <td>32.179688</td>\n",
              "      <td>33.542297</td>\n",
              "      <td>36.533836</td>\n",
              "      <td>36.158222</td>\n",
              "      <td>35.150593</td>\n",
              "      <td>32.027397</td>\n",
              "      <td>26.254917</td>\n",
              "      <td>17.983868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.400309</td>\n",
              "      <td>16.737888</td>\n",
              "      <td>17.519260</td>\n",
              "      <td>22.728565</td>\n",
              "      <td>22.528677</td>\n",
              "      <td>24.225760</td>\n",
              "      <td>31.314346</td>\n",
              "      <td>27.983013</td>\n",
              "      <td>22.823448</td>\n",
              "      <td>20.503525</td>\n",
              "      <td>...</td>\n",
              "      <td>27.310856</td>\n",
              "      <td>23.909794</td>\n",
              "      <td>18.724120</td>\n",
              "      <td>21.818403</td>\n",
              "      <td>24.910782</td>\n",
              "      <td>21.403605</td>\n",
              "      <td>21.136051</td>\n",
              "      <td>19.617165</td>\n",
              "      <td>16.570320</td>\n",
              "      <td>12.288887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.134473</td>\n",
              "      <td>13.481317</td>\n",
              "      <td>16.497002</td>\n",
              "      <td>20.368069</td>\n",
              "      <td>14.509150</td>\n",
              "      <td>17.061584</td>\n",
              "      <td>24.823020</td>\n",
              "      <td>20.653173</td>\n",
              "      <td>19.454735</td>\n",
              "      <td>14.869041</td>\n",
              "      <td>...</td>\n",
              "      <td>21.883310</td>\n",
              "      <td>25.639480</td>\n",
              "      <td>23.540054</td>\n",
              "      <td>18.858322</td>\n",
              "      <td>20.297009</td>\n",
              "      <td>21.009579</td>\n",
              "      <td>17.495934</td>\n",
              "      <td>13.776319</td>\n",
              "      <td>13.104317</td>\n",
              "      <td>9.069902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.885613</td>\n",
              "      <td>8.869980</td>\n",
              "      <td>12.384069</td>\n",
              "      <td>11.666620</td>\n",
              "      <td>8.762781</td>\n",
              "      <td>14.657253</td>\n",
              "      <td>16.756500</td>\n",
              "      <td>12.666725</td>\n",
              "      <td>8.871258</td>\n",
              "      <td>3.851370</td>\n",
              "      <td>...</td>\n",
              "      <td>14.630124</td>\n",
              "      <td>15.115923</td>\n",
              "      <td>17.144138</td>\n",
              "      <td>16.288240</td>\n",
              "      <td>16.407455</td>\n",
              "      <td>16.913385</td>\n",
              "      <td>9.809426</td>\n",
              "      <td>9.440727</td>\n",
              "      <td>8.185134</td>\n",
              "      <td>5.845839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.854179</td>\n",
              "      <td>12.262621</td>\n",
              "      <td>10.831870</td>\n",
              "      <td>4.002755</td>\n",
              "      <td>9.354394</td>\n",
              "      <td>13.389982</td>\n",
              "      <td>14.233492</td>\n",
              "      <td>10.481882</td>\n",
              "      <td>5.950897</td>\n",
              "      <td>2.667422</td>\n",
              "      <td>...</td>\n",
              "      <td>15.118452</td>\n",
              "      <td>14.953615</td>\n",
              "      <td>13.677976</td>\n",
              "      <td>15.595757</td>\n",
              "      <td>12.006489</td>\n",
              "      <td>10.840181</td>\n",
              "      <td>10.435387</td>\n",
              "      <td>7.242203</td>\n",
              "      <td>7.516584</td>\n",
              "      <td>4.122503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.239115</td>\n",
              "      <td>2.921768</td>\n",
              "      <td>0.449536</td>\n",
              "      <td>-1.447572</td>\n",
              "      <td>8.025484</td>\n",
              "      <td>9.722061</td>\n",
              "      <td>10.611401</td>\n",
              "      <td>8.393124</td>\n",
              "      <td>1.459947</td>\n",
              "      <td>0.641023</td>\n",
              "      <td>...</td>\n",
              "      <td>11.150479</td>\n",
              "      <td>10.347811</td>\n",
              "      <td>4.785758</td>\n",
              "      <td>9.953649</td>\n",
              "      <td>6.019490</td>\n",
              "      <td>2.910423</td>\n",
              "      <td>5.969234</td>\n",
              "      <td>8.232852</td>\n",
              "      <td>6.724492</td>\n",
              "      <td>6.033055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.228742</td>\n",
              "      <td>8.585993</td>\n",
              "      <td>11.038528</td>\n",
              "      <td>5.022841</td>\n",
              "      <td>4.395417</td>\n",
              "      <td>3.941920</td>\n",
              "      <td>10.484508</td>\n",
              "      <td>8.496041</td>\n",
              "      <td>5.036035</td>\n",
              "      <td>12.292791</td>\n",
              "      <td>...</td>\n",
              "      <td>15.869504</td>\n",
              "      <td>11.760733</td>\n",
              "      <td>5.837637</td>\n",
              "      <td>10.689942</td>\n",
              "      <td>8.251028</td>\n",
              "      <td>2.205105</td>\n",
              "      <td>4.517925</td>\n",
              "      <td>9.932086</td>\n",
              "      <td>8.678764</td>\n",
              "      <td>4.427045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2.442136</td>\n",
              "      <td>5.416662</td>\n",
              "      <td>3.625821</td>\n",
              "      <td>-2.217569</td>\n",
              "      <td>-2.001754</td>\n",
              "      <td>3.055751</td>\n",
              "      <td>2.921979</td>\n",
              "      <td>1.594232</td>\n",
              "      <td>2.123627</td>\n",
              "      <td>2.591272</td>\n",
              "      <td>...</td>\n",
              "      <td>3.640095</td>\n",
              "      <td>2.895083</td>\n",
              "      <td>2.217961</td>\n",
              "      <td>4.927725</td>\n",
              "      <td>3.451984</td>\n",
              "      <td>1.138815</td>\n",
              "      <td>-1.782372</td>\n",
              "      <td>-0.798526</td>\n",
              "      <td>1.381832</td>\n",
              "      <td>2.345471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.308006</td>\n",
              "      <td>1.849368</td>\n",
              "      <td>2.648895</td>\n",
              "      <td>3.060864</td>\n",
              "      <td>3.704577</td>\n",
              "      <td>6.603056</td>\n",
              "      <td>7.588957</td>\n",
              "      <td>9.453242</td>\n",
              "      <td>10.527960</td>\n",
              "      <td>4.816059</td>\n",
              "      <td>...</td>\n",
              "      <td>8.264572</td>\n",
              "      <td>7.421254</td>\n",
              "      <td>11.416150</td>\n",
              "      <td>8.694925</td>\n",
              "      <td>3.390199</td>\n",
              "      <td>5.608705</td>\n",
              "      <td>6.225214</td>\n",
              "      <td>3.567305</td>\n",
              "      <td>1.585533</td>\n",
              "      <td>2.961648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2.780722</td>\n",
              "      <td>4.516361</td>\n",
              "      <td>4.977440</td>\n",
              "      <td>5.687684</td>\n",
              "      <td>3.321391</td>\n",
              "      <td>4.310385</td>\n",
              "      <td>1.644539</td>\n",
              "      <td>4.452641</td>\n",
              "      <td>6.461669</td>\n",
              "      <td>4.538523</td>\n",
              "      <td>...</td>\n",
              "      <td>6.916524</td>\n",
              "      <td>3.872615</td>\n",
              "      <td>5.403200</td>\n",
              "      <td>1.245299</td>\n",
              "      <td>-4.280363</td>\n",
              "      <td>-4.531428</td>\n",
              "      <td>-4.534841</td>\n",
              "      <td>-9.869007</td>\n",
              "      <td>-6.401797</td>\n",
              "      <td>-0.532115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.477061</td>\n",
              "      <td>2.782973</td>\n",
              "      <td>4.959840</td>\n",
              "      <td>8.554922</td>\n",
              "      <td>8.908003</td>\n",
              "      <td>5.128218</td>\n",
              "      <td>5.568866</td>\n",
              "      <td>10.190098</td>\n",
              "      <td>6.383940</td>\n",
              "      <td>6.805264</td>\n",
              "      <td>...</td>\n",
              "      <td>4.904903</td>\n",
              "      <td>4.429753</td>\n",
              "      <td>7.980596</td>\n",
              "      <td>3.414380</td>\n",
              "      <td>-3.402398</td>\n",
              "      <td>-6.213781</td>\n",
              "      <td>-3.878690</td>\n",
              "      <td>-9.181259</td>\n",
              "      <td>-2.600746</td>\n",
              "      <td>2.145145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.020112</td>\n",
              "      <td>4.855131</td>\n",
              "      <td>5.163251</td>\n",
              "      <td>14.330421</td>\n",
              "      <td>15.317526</td>\n",
              "      <td>6.801951</td>\n",
              "      <td>8.997994</td>\n",
              "      <td>11.389247</td>\n",
              "      <td>6.045928</td>\n",
              "      <td>7.115082</td>\n",
              "      <td>...</td>\n",
              "      <td>8.356026</td>\n",
              "      <td>9.193071</td>\n",
              "      <td>10.429809</td>\n",
              "      <td>10.300892</td>\n",
              "      <td>3.572683</td>\n",
              "      <td>-0.785625</td>\n",
              "      <td>3.086043</td>\n",
              "      <td>0.307965</td>\n",
              "      <td>1.042486</td>\n",
              "      <td>2.162609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.289417</td>\n",
              "      <td>4.392704</td>\n",
              "      <td>5.398010</td>\n",
              "      <td>7.555681</td>\n",
              "      <td>7.504780</td>\n",
              "      <td>8.120828</td>\n",
              "      <td>9.922593</td>\n",
              "      <td>7.822845</td>\n",
              "      <td>3.229239</td>\n",
              "      <td>3.489827</td>\n",
              "      <td>...</td>\n",
              "      <td>6.335666</td>\n",
              "      <td>7.366229</td>\n",
              "      <td>4.571144</td>\n",
              "      <td>3.464195</td>\n",
              "      <td>0.258484</td>\n",
              "      <td>-2.342484</td>\n",
              "      <td>-1.303418</td>\n",
              "      <td>-1.448322</td>\n",
              "      <td>-0.987339</td>\n",
              "      <td>-0.223155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.416011</td>\n",
              "      <td>6.048285</td>\n",
              "      <td>7.828956</td>\n",
              "      <td>7.707705</td>\n",
              "      <td>7.447975</td>\n",
              "      <td>7.089395</td>\n",
              "      <td>6.667765</td>\n",
              "      <td>4.608913</td>\n",
              "      <td>2.673733</td>\n",
              "      <td>1.044449</td>\n",
              "      <td>...</td>\n",
              "      <td>7.329278</td>\n",
              "      <td>10.482709</td>\n",
              "      <td>0.414825</td>\n",
              "      <td>3.431669</td>\n",
              "      <td>7.210251</td>\n",
              "      <td>-0.021464</td>\n",
              "      <td>-5.898850</td>\n",
              "      <td>-4.855162</td>\n",
              "      <td>-3.154200</td>\n",
              "      <td>0.083367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4.584046</td>\n",
              "      <td>1.266698</td>\n",
              "      <td>2.853934</td>\n",
              "      <td>3.867961</td>\n",
              "      <td>4.031549</td>\n",
              "      <td>1.301042</td>\n",
              "      <td>-3.213294</td>\n",
              "      <td>-0.666927</td>\n",
              "      <td>-0.653931</td>\n",
              "      <td>-5.726377</td>\n",
              "      <td>...</td>\n",
              "      <td>6.354600</td>\n",
              "      <td>3.372196</td>\n",
              "      <td>-7.436252</td>\n",
              "      <td>-0.069299</td>\n",
              "      <td>3.742786</td>\n",
              "      <td>1.294925</td>\n",
              "      <td>-2.002482</td>\n",
              "      <td>-7.301378</td>\n",
              "      <td>-4.333294</td>\n",
              "      <td>-0.689210</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 130 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5a6000-3463-4a17-9524-2a08d533bf6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de5a6000-3463-4a17-9524-2a08d533bf6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de5a6000-3463-4a17-9524-2a08d533bf6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fdbcd5e-22d9-42bd-8739-945b7452ac03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fdbcd5e-22d9-42bd-8739-945b7452ac03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fdbcd5e-22d9-42bd-8739-945b7452ac03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs.shape"
      ],
      "metadata": {
        "id": "RsebnvEFc2WM",
        "outputId": "9c24adbd-5a7f-46ee-a2ab-1c16a2b53d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 130)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [f'MFCC {i}' for i in range(1, 21)]\n",
        "columns.append('Speaker')\n",
        "df = pd.DataFrame(columns=columns)\n",
        "for file_name in file_names:\n",
        "  if file_name.split('.')[-1] != \"m4a\":\n",
        "    continue\n",
        "  file_path = directory_path + file_name\n",
        "  signal, sr = librosa.load(file_path, duration=3)\n",
        "  mfccs = librosa.feature.mfcc(y=signal, n_mfcc=20, sr=sr)\n",
        "  mfcc_vector = get_mfccs_mean_vector(mfccs)\n",
        "  mfcc_vector = np.append(mfcc_vector, speaker)\n",
        "  df = df.append(pd.Series(mfcc_vector, index=df.columns), ignore_index=True)\n",
        "df.to_csv(f'{output_path}{speaker}_3sec.csv', index=False)\n",
        "df = pd.read_csv(f'{output_path}{speaker}.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "durveMaAIeTl",
        "outputId": "428c6712-d0cc-48ca-f1aa-efa09baa1cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-18e804f78b18>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    mfcc_vector = np.append(mfcc_vector, speaker)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directories = ['Sherif', 'Omar', 'Renad', 'Reem', 'Youssef']"
      ],
      "metadata": {
        "id": "KaVHWzqMg99F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set the path to the directory containing your dataset\n",
        "dataset_directory = \"/content/drive/MyDrive/thesis_models/mini_dataset/\"\n",
        "\n",
        "# Lists to store features and labels\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "# Iterate through each directory in the dataset\n",
        "for directory in os.listdir(dataset_directory):\n",
        "    if directory not in directories:\n",
        "      continue\n",
        "    if os.path.isdir(os.path.join(dataset_directory, directory)):\n",
        "        # Get the path to the Excel file in the current directory\n",
        "        excel_file_path = os.path.join(dataset_directory, directory, f\"{directory}.csv\")\n",
        "\n",
        "        # Read the Excel file\n",
        "        df = pd.read_csv(excel_file_path)\n",
        "\n",
        "        # Assuming the last column is the target/label column\n",
        "        X = df.iloc[:, :-1].values  # Features\n",
        "        y = df.iloc[:, -1].values   # Labels\n",
        "\n",
        "        # Append the features and labels to the lists\n",
        "        X_list.append(X)\n",
        "        y_list.append(y)\n",
        "\n",
        "# Concatenate the lists to create the final feature and label arrays\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y = np.concatenate(y_list, axis=0)\n",
        "# print(X)\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7) #, test_size=0.1, random_state=42\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0)\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6llL-HdJb0y",
        "outputId": "2df8dd09-cb38-4cff-bb91-c384d663b374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set the path to the directory containing your dataset\n",
        "dataset_directory = \"/content/drive/MyDrive/thesis_models/mini_dataset/\"\n",
        "\n",
        "# Lists to store features and labels\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "# Iterate through each directory in the dataset\n",
        "for directory in os.listdir(dataset_directory):\n",
        "    if directory not in directories:\n",
        "      continue\n",
        "    if os.path.isdir(os.path.join(dataset_directory, directory)):\n",
        "        # Get the path to the Excel file in the current directory\n",
        "        excel_file_path = os.path.join(dataset_directory, directory, f\"{directory}.csv\")\n",
        "\n",
        "        # Read the Excel file\n",
        "        df = pd.read_csv(excel_file_path)\n",
        "\n",
        "        # Assuming the last column is the target/label column\n",
        "        X = df.iloc[:, :-1].values  # Features\n",
        "        y = df.iloc[:, -1].values   # Labels\n",
        "\n",
        "        # Append the features and labels to the lists\n",
        "        X_list.append(X)\n",
        "        y_list.append(y)\n",
        "\n",
        "# Concatenate the lists to create the final feature and label arrays\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "\n",
        "# Use LabelEncoder to convert string labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(np.concatenate(y_list, axis=0))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7) #, test_size=0.2, random_state=42\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEO-LBaCQFCS",
        "outputId": "1b351f3d-90a1-47a0-92d0-d0f225d14cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set the path to the directory containing your dataset\n",
        "dataset_directory = \"/content/drive/MyDrive/thesis_models/mini_dataset/\"\n",
        "\n",
        "# Lists to store features and labels\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "# Dictionary to store the mapping from numerical labels to class names\n",
        "class_mapping = {}\n",
        "\n",
        "# Iterate through each directory in the dataset\n",
        "for directory in os.listdir(dataset_directory):\n",
        "    if directory not in directories:\n",
        "        continue\n",
        "    if os.path.isdir(os.path.join(dataset_directory, directory)):\n",
        "        # Get the path to the Excel file in the current directory\n",
        "        excel_file_path = os.path.join(dataset_directory, directory, f\"{directory}.csv\")\n",
        "\n",
        "        # Read the Excel file\n",
        "        df = pd.read_csv(excel_file_path)\n",
        "\n",
        "        # Assuming the last column is the target/label column\n",
        "        X = df.iloc[:, :-1].values  # Features\n",
        "        y = df.iloc[:, -1].values   # Labels\n",
        "\n",
        "        # Append the features and labels to the lists\n",
        "        X_list.append(X)\n",
        "        y_list.append(y)\n",
        "\n",
        "        # Update the class mapping without using LabelEncoder\n",
        "        class_mapping.update({label: class_name for label, class_name in zip(y, y)})\n",
        "\n",
        "# Concatenate the lists to create the final feature and label arrays\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y_all = np.concatenate(y_list, axis=0)\n",
        "\n",
        "# Use LabelEncoder to convert string labels to integers for training\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_all)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded, train_size=0.7)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_encoded = xgb_model.predict(X_test)\n",
        "\n",
        "# Map the predicted numerical labels back to class names using the class_mapping dictionary\n",
        "predicted_class_names = [class_mapping[label] for label in label_encoder.inverse_transform(y_pred_encoded)]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(label_encoder.inverse_transform(y_test_encoded), label_encoder.inverse_transform(y_pred_encoded))\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "\n",
        "# Display the predicted class names\n",
        "print(\"Predicted Class Names:\", predicted_class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JDtkF60_gdm",
        "outputId": "64ae6690-cc76-41ce-8070-f3a11135df42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.86667\n",
            "Predicted Class Names: ['Sherif', 'Renad', 'Reem', 'Renad', 'Renad', 'Youssef', 'Reem', 'Sherif', 'Omar', 'Renad', 'Renad', 'Omar', 'Youssef', 'Sherif', 'Sherif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in class_mapping.items():\n",
        "  print(key, value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0WjqC87NG55",
        "outputId": "ad2ce90c-817d-4ba6-d594-e64cb910a94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sherif Sherif\n",
            "Youssef Youssef\n",
            "Omar Omar\n",
            "Renad Renad\n",
            "Reem Reem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5_eK00W_4Y3",
        "outputId": "d518922f-8f86-4425-b67f-89630cd4804c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 1, 2, 2, 4, 1, 3, 0, 2, 2, 0, 4, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10PXhF2xmLZ4",
        "outputId": "d24fe9e1-e3c0-4121-9380-b210e41316e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 1, 1, 2, 4, 1, 3, 0, 2, 2, 0, 1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = [[-340.78452,136.54994,6.28157,22.479836,5.836398,3.624558,-6.715408,-3.530711,-5.688966,1.43254,-1.8756343,2.1192057,-0.36051726,-4.1750746,-1.2043107,1.572028,-4.466659,-5.4007607,2.8591537,-4.360394]]"
      ],
      "metadata": {
        "id": "VQm5AA_0AoWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_sample_encoded = xgb_model.predict(test_sample)\n",
        "speaker = [class_mapping[label] for label in label_encoder.inverse_transform(y_pred_sample_encoded)]\n",
        "speaker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAZVvxbDAr18",
        "outputId": "c8b148f7-0bf9-4f81-c8d8-4ce24f6c2558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Omar']"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPH8bd8XArrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmjpb1FdAqM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GV8ZvtbvocT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_cnn(num_classes):\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X.shape[1], 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')  # Assuming three classes\n",
        "  ])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "CQwUxT2ooTsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "num_features = 20"
      ],
      "metadata": {
        "id": "fWEd_Ag9rJZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) #, test_size=0.2, random_state=42"
      ],
      "metadata": {
        "id": "hPWNvojGvd_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(Dense(128, input_dim=num_features, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(5, activation='softmax'))  # softmax for 5 classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=5)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_one_hot, epochs=1000, batch_size=64) #, validation_split=0.2\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test_one_hot)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "IzMKBgeUoinT",
        "outputId": "b679d6ca-5ce6-40c8-e784-bc0066ce21d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-08453d1a16d7>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Convert labels to one-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my_train_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my_test_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Renad'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zkds5-syMMq",
        "outputId": "0352d067-476b-4b3b-edaa-9370add15ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Renad', 'Reem', 'Omar', 'Renad', 'Omar', 'Reem', 'Omar', 'Sherif',\n",
              "       'Sherif', 'Sherif', 'Omar', 'Renad', 'Reem', 'Omar', 'Renad',\n",
              "       'Sherif', 'Reem', 'Omar', 'Omar', 'Reem', 'Renad', 'Youssef',\n",
              "       'Sherif', 'Reem', 'Youssef', 'Youssef', 'Renad', 'Renad', 'Reem',\n",
              "       'Youssef', 'Youssef', 'Youssef', 'Omar', 'Omar', 'Omar', 'Sherif',\n",
              "       'Youssef', 'Reem', 'Sherif', 'Sherif'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ5fUJf9oq5F",
        "outputId": "2ffd9a00-4f98-4398-f8b4-7e433e7968d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, 4, 0, 0, 2, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)\n",
        "predicted_classes = np.argmax(preds, axis=1)\n",
        "predicted_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC9KJUa7qJN5",
        "outputId": "35a2de95-e9bb-4aaa-cb43-d4d7f8659ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 138ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, 4, 1, 0, 2, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_names = {\n",
        "    1: 'Sherif',\n",
        "    2: 'Reem',\n",
        "    3: 'Renad',\n",
        "    4: 'Omar',\n",
        "    5: 'Youssef'\n",
        "}\n",
        "predicted_class = map_names[1]\n",
        "predicted_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7fYw2UIk-EuH",
        "outputId": "b825db71-64fd-45df-dcc4-866e063998a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sherif'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier()\n",
        "\n",
        "# Train the XGBoost model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Ua_Zvhpy7W",
        "outputId": "5e128b6c-8b89-4ec9-95ac-29d618ef08f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80000\n"
          ]
        }
      ]
    }
  ]
}